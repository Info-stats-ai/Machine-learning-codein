{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6082eef4-1b1f-4713-a13a-0181fba267a9",
   "metadata": {},
   "source": [
    "### PCA\n",
    "- Used in feature extraction\n",
    "- As I mentioned earlier let suppose we have 5 features a, b, c, d, e , in feature extraction we create feature of ab, c, d, e  out of which let say c is irrelevant , so we can remove this feature ( this removal of feature is part of  feature selection)\n",
    "- It is a Dimentionality reduction  Technique\n",
    "- Principal Component Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0fee0-23a2-4b84-a539-e31362fa80bb",
   "metadata": {},
   "source": [
    "### Application Of PCA \n",
    "- Data compression : 50 dimentions to 5 dimentions\n",
    "- Example : x1, x2 , we can plot both x and y\n",
    "- compressing the data 2d to 1d --->>> we need a line\n",
    "- converting 3d to 2d -->> we need a plane z1, z2\n",
    "- coverting 3d to 1d --.. project all the data on a line , now all point in 1D is our new data set\n",
    "-  for constant value of y or x axis --->> variance is zero as spread is 0.\n",
    "-  spread is information , because spread provide lot of info about the features\n",
    "-  How should we perform PCA -- We need to make sure that variance should be retained.\n",
    "-  It is also  used in Data Visualization\n",
    "-  It speeds up the computation\n",
    "-  Uses less memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e7b7f0-08ca-4b02-b24b-9784f87b05c4",
   "metadata": {},
   "source": [
    "### PCA Objective:\n",
    "- Data Preprocessing : normalization/ Standardization\n",
    "- If Spread is more , it means it explains more data\n",
    "- compressed data with higher spread is preferred , ie we try project the points in new dimentions with larger spread.\n",
    "- Projection error : perpendicular distance between the point in  when it was in the actual dimention before applying PCA and the  same point when projected in another dimention after applying PCA or any other analysis\n",
    "- We need Minimize the projection error:\n",
    "- projection error : is = mininmize{summation(i to m ) (projection-error)**2}.\n",
    "- We need to  mininmize{summation(i to m ) (projection-error)**2}.\n",
    "- We have to maximize the variance or minimize the projection error.\n",
    "- 2d to 1d : find a vector (direction or axis) on to which to project your data so, is to minimize the projection error.\n",
    "- nD to kd , find k vectors (u1, u2,...uk)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce99d7b-1d24-421a-846e-545acaa721c1",
   "metadata": {},
   "source": [
    "### PCA Algo\n",
    "\n",
    "\n",
    "#### Step 1:\n",
    "\n",
    "-  Pre- processing (standarization)\n",
    "  \n",
    "#### Step 2:\n",
    "\n",
    "-  Compute Covariance matrix :\n",
    "-  For example for 2dimentions covariance matrix will be 2X2.\n",
    "-  Elements are cov(x1, x1), cov(x1,x2), cov(x2, x1), cov(x2, x2).\n",
    "-  Co - variance(x1, x1) = summation(i =1 to m) (x1 - u)**2/ (N -1).\n",
    "-  Co - variance(x1, x2) = summation(i =1 to m) (x1 - u1)(x2-u2)/ (N -1).\n",
    "  \n",
    "#### Step 3:\n",
    "\n",
    "-  Find u(eigen vectors) of covariance matrix.\n",
    "-  To find eigen vectors using SVD-->>> Singular Value Decomposition.\n",
    "-  u, s, v = SVD(covariance_matrix).\n",
    "-  we just need u not s and v.-->> right now\n",
    "-  using svd we get u\n",
    "-  If we have 5 features  and data have m examples , than the covariance matrix will be size 5X5(matrix)\n",
    "-  u.shape = (n, n) as no. of features is n\n",
    "-  eigen vectors are calculated in for all features \n",
    "-  for example u1....un are eigen vectors but we break down after imparting these eigen vectors in k dimentions\n",
    "-  u_reduced = (nXk)\n",
    "\n",
    "\n",
    "#### Step 4:\n",
    "\n",
    "- Projection Part:\n",
    "- u_reduced = (nXk)\n",
    "- X = nX1\n",
    "- z = u_reduced.T * X\n",
    "- z = kX1\n",
    "\n",
    "#### Summary of PCA:\n",
    "\n",
    "- X -->>(m, n)\n",
    "- preprocessing\n",
    "- covariance , covar is (n,n)\n",
    "- eigen vector using SVD we take u values from covariance matrix\n",
    "- right now shape of u is (n, n)--because the covariance matrix has (n,n ) shape\n",
    "- we will slice the columns  and make u_reduced = (n, k)\n",
    "- project the data\n",
    "- z = u_reduced.T * X\n",
    "- z = mXk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d009f361-a183-4dad-842d-42b70937fbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.11/site-packages (from keras) (3.9.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a06df5b-8010-48fe-8542-addb28b4f412",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: dlopen(/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 0x0006): Symbol not found: __ZN6snappy11RawCompressEPKcmPcPm\n  Referenced from: <A27E381C-E452-323F-830B-3476E75DA88A> /opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n  Expected in:     <F4610B3E-77CA-35FF-A986-DF0C809E6B61> /opt/anaconda3/envs/testenv/lib/libsnappy.1.1.10.dylib\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py:64\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 0x0006): Symbol not found: __ZN6snappy11RawCompressEPKcmPcPm\n  Referenced from: <A27E381C-E452-323F-830B-3476E75DA88A> /opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n  Expected in:     <F4610B3E-77CA-35FF-A986-DF0C809E6B61> /opt/anaconda3/envs/testenv/lib/libsnappy.1.1.10.dylib",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n",
      "File \u001b[0;32m/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/keras/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/__init__.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/__init__.py:40\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py:83\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m   msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124mSee https://www.tensorflow.org/install/errors\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124mfor some common reasons and solutions.  Include the entire stack trace\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124mabove this error message when asking for help.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m%\u001b[39m traceback\u001b[38;5;241m.\u001b[39mformat_exc()\n\u001b[0;32m---> 83\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: dlopen(/opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 0x0006): Symbol not found: __ZN6snappy11RawCompressEPKcmPcPm\n  Referenced from: <A27E381C-E452-323F-830B-3476E75DA88A> /opt/anaconda3/envs/testenv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n  Expected in:     <F4610B3E-77CA-35FF-A986-DF0C809E6B61> /opt/anaconda3/envs/testenv/lib/libsnappy.1.1.10.dylib\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f260fa-c9f8-4895-bdcc-03cc4278444f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e6222-5f2d-4e69-a606-fd2c656a3b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a23368-5dfa-48e5-a34b-a2fcf24a61fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f2d34-6e31-448c-b76c-9ef103874a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
