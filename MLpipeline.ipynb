{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7349d1a9-003e-437b-9899-e42718d36a87",
   "metadata": {},
   "source": [
    "### Machine Learning Pipeline\n",
    "- Data Generation/Collection\n",
    "- Data cleaning/ Feature Engineering\n",
    "- Alogrithms to find intreseting patterns\n",
    "- Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca493c7-4add-46f3-93f5-5606e198bd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ad68e23-b1b4-4f6a-9e27-efb95fdb9d26",
   "metadata": {},
   "source": [
    "#### Supervised Learning \n",
    "- spam detection\n",
    "- document classfication - multilabel \n",
    "- NLP\n",
    "- Image Classification and detection\n",
    "- sequence Processing like -speech , music\n",
    "- Predictive Analysis - stock analysis etc.\n",
    "#### Unsupervised Learning \n",
    "- No supervision\n",
    "- Grouping similar data points - clusterring\n",
    "- data is not labelled\n",
    "- algo try to find patterns\n",
    "#### Semi-Suprvised Learning\n",
    "- manually label some data points\n",
    "- helps to improve our outputs\n",
    "- ex - 10 million tweets labelling such data is very difficult , but we can use\n",
    "- some shortcuts and then label some of them\n",
    "#### Reinforcement Learning\n",
    "- We will  Learn to AI bot\n",
    "- concept of Ai based agent /object\n",
    "- Agent : which interacts with the environment\n",
    "- each inputs a different state\n",
    "- Enviroment gives rewards and punishments\n",
    "- final state : game over(state is in between) or game won (last state of game)\n",
    "- Goal is maximize the total rewards --> we need algo \n",
    "- We need to find game policy\n",
    "- posterior and prior probability\n",
    "- One popular technique Deep Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5835d87-7b30-4e82-b988-668e87f67a2b",
   "metadata": {},
   "source": [
    "#### Regression \n",
    "#### Classifcation - output is one of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b728dc29-d04d-4b83-8573-421f1d1bf1d0",
   "metadata": {},
   "source": [
    "### How algo works \n",
    "- it takes Traning data\n",
    "- learns a hypothesis , ie data is given to algo and\n",
    "- it generates a hypo\n",
    "- this hypo accepts the testing data(unseen data) and generates output y-test (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237eb3b1-832f-4cf6-ab03-d45cefd098f8",
   "metadata": {},
   "source": [
    "#### hypothesis is just a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097fb3a7-8e97-4f94-884a-a469957a82a4",
   "metadata": {},
   "source": [
    "### Loss:\n",
    "- Regression: minimize least square error\n",
    "- classification : minimize no. of misclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68797ba7-884f-4c2e-a782-dc9d16746125",
   "metadata": {},
   "source": [
    "### Overfitting \n",
    "- More accurate\n",
    "- less generalized\n",
    "- Higher accuracy on traninging data but lesser on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc4aba-e442-4576-a9ca-6df16b70dcba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
